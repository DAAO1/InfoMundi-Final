# ğŸŒ InfoMundi --- Proyecto Final ProgramaciÃ³n Web

## DescripciÃ³n

**InfoMundi** es una aplicaciÃ³n web acadÃ©mica que integra **frontend,
backend, base de datos y pipeline ETL**.\
El sistema permite:

-   Buscar paÃ­ses usando la **API de RestCountries**.\
-   Guardar paÃ­ses como **favoritos** en una base de datos MySQL.\
-   Ejecutar un **pipeline ETL** (manual o automÃ¡tico cada 5 minutos)
    que limpia y normaliza los datos.\
-   Generar **respaldos en CSV y logs JSON**.\
-   Visualizar los datos limpios en una tabla desde el frontend.

------------------------------------------------------------------------

## TecnologÃ­as utilizadas

-   **Frontend**: HTML5, CSS3, JavaScript (Fetch API)\
-   **Backend**: FastAPI, Uvicorn\
-   **ORM**: SQLAlchemy\
-   **Base de datos**: MySQL 8\
-   **ETL**: pandas\
-   **AutomatizaciÃ³n**: APScheduler, Prefect (opcional)\
-   **GestiÃ³n de variables**: python-dotenv\
-   **ContenerizaciÃ³n**: Docker + Docker Compose

------------------------------------------------------------------------

## Estructura del proyecto

    proyecto_final_programacion_web/
    â”œâ”€â”€ backend/
    â”‚   â”œâ”€â”€ main.py             # API con FastAPI
    â”‚   â”œâ”€â”€ database.py         # ConexiÃ³n a MySQL (.env)
    â”‚   â”œâ”€â”€ models.py           # Modelo Favorito
    â”‚   â”œâ”€â”€ etl_pipeline.py     # Script ETL
    â”‚   â””â”€â”€ __init__.py
    â”œâ”€â”€ frontend/
    â”‚   â”œâ”€â”€ index.html          # Interfaz web
    â”‚   â”œâ”€â”€ styles.css          # Estilos
    â”‚   â””â”€â”€ script.js           # LÃ³gica JS (fetch APIs)
    â”œâ”€â”€ pipeline/
    â”‚   â”œâ”€â”€ backups/            # CSV generados por ETL
    â”‚   â””â”€â”€ logs/               # Logs JSON de ETL
    â”œâ”€â”€ database/
    â”‚   â””â”€â”€ crear_infomundi.sql # Script inicial SQL
    â”œâ”€â”€ requirements.txt        # Dependencias Python
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ .env                    # Variables (no subir al repo)
    â””â”€â”€ README.md

------------------------------------------------------------------------

## InstalaciÃ³n y ejecuciÃ³n local

### 1. Clonar repositorio

``` bash
git clone https://github.com/usuario/proyecto_final_programacion_web.git
cd proyecto_final_programacion_web
```

### 2. Crear entorno virtual e instalar dependencias

``` bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt
```

### 3. Configurar MySQL

Ejecuta el script de creaciÃ³n:

``` bash
mysql -uroot -p < database/crear_infomundi.sql
```

Agrega un archivo `.env` en la raÃ­z:

    DATABASE_URL=mysql+pymysql://root:<PASSWORD>@localhost:3306/infomundiF
    ALLOWED_ORIGINS=http://localhost:8080,http://127.0.0.1:8080

### 4. Levantar backend

``` bash
uvicorn backend.main:app --reload
```

DocumentaciÃ³n interactiva: <http://127.0.0.1:8000/docs>

### 5. Levantar frontend

-   Con **Live Server** en VSCode â†’ `frontend/index.html`\
-   O sirviendo el frontend desde FastAPI (opcional).

------------------------------------------------------------------------

## EjecuciÃ³n con Docker Compose

``` bash
docker compose down -v
docker compose up --build
```

-   API: <http://localhost:8000/docs>\
-   Frontend: <http://localhost:8080>

------------------------------------------------------------------------

## Endpoints principales

  MÃ©todo   Endpoint              DescripciÃ³n
  -------- --------------------- ------------------------
  GET      `/favoritos`          Lista favoritos
  POST     `/favoritos`          Crear favorito
  GET      `/favoritos/{id}`     Obtener por id
  PUT      `/favoritos/{id}`     Actualizar favorito
  DELETE   `/favoritos/{id}`     Eliminar favorito
  POST     `/api/pipeline/run`   Ejecutar ETL manual
  GET      `/api/cleaned_data`   Devolver datos limpios

------------------------------------------------------------------------

## ETL y respaldos

-   **AutomÃ¡tico cada 5 minutos** gracias a APScheduler.\
-   **EjecuciÃ³n manual** vÃ­a `POST /api/pipeline/run`.\
-   Respalda en `pipeline/backups/`:
    -   `raw_backup_YYYYMMDD_HHMMSS.csv`\
    -   `cleaned_backup_YYYYMMDD_HHMMSS.csv`\
    -   `etl_log_YYYYMMDD_HHMMSS.json`

------------------------------------------------------------------------

## Evidencias de cumplimiento

-   API CRUD en FastAPI.\
-   Base de datos inicializada vÃ­a script SQL.\
-   Frontend que consume el API y muestra datos.\
-   ETL con pandas + respaldos CSV/JSON.\
-   AutomatizaciÃ³n con APScheduler y Prefect.\
-   Docker Compose con servicios: DB + API + Frontend.

------------------------------------------------------------------------

## Requisitos

-   Python 3.12\
-   MySQL 8\
-   Docker Desktop (opcional)\
-   Prefect CLI (si se usa orquestaciÃ³n)
